{
 "cells": [
  {
   "cell_type": "code",
   "id": "7aa372910813b134",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T14:38:41.670085Z",
     "start_time": "2025-05-06T14:38:38.881453Z"
    }
   },
   "source": [
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "# from time import time\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "6a89663d966ead91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T14:38:43.810413Z",
     "start_time": "2025-05-06T14:38:41.679863Z"
    }
   },
   "source": [
    "class BC_2D:\n",
    "    def __init__(self, left, right, up, down):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            left, right, up, down: (alpha, beta, f(t))\n",
    "        \"\"\"\n",
    "        # alpha*u + beta*u_x + gamma*u_y = f(t)\n",
    "        self.left_alpha, self.left_beta, self.left_func = left\n",
    "        self.right_alpha, self.right_beta, self.right_func = right\n",
    "        self.up_alpha, self.up_beta, self.up_func = up\n",
    "        self.down_alpha, self.down_beta, self.down_func = down\n",
    "\n",
    "    @torch.compile\n",
    "    def apply(self, simu):\n",
    "        gamma_left = self.left_beta / simu.dx\n",
    "        gamma_right = self.right_beta / simu.dx\n",
    "        gamma_up = self.up_beta / simu.dx\n",
    "        gamma_down = self.down_beta / simu.dx\n",
    "\n",
    "        simu.grid[1:-1,0] = (self.left_func(simu.x_coord_tensor[0,:], simu.y_coord_tensor[:,0], simu.cur_time) - gamma_left * simu.grid[1:-1,1]) / (self.left_alpha - gamma_left)\n",
    "\n",
    "\n",
    "        # Right boundary\n",
    "        simu.grid[1:-1,-1] = (self.right_func(simu.x_coord_tensor[0,:], simu.y_coord_tensor[:,0], simu.cur_time) + gamma_right * simu.grid[1:-1,-2]) / (self.right_alpha + gamma_right)\n",
    "\n",
    "        # Left boundary\n",
    "        simu.grid[0,1:-1] = (self.up_func(simu.x_coord_tensor[0,:], simu.y_coord_tensor[:,0], simu.cur_time) - gamma_up * simu.grid[1,1:-1]) / (self.up_alpha - gamma_up)\n",
    "\n",
    "        # Down boundary\n",
    "        simu.grid[-1,1:-1] = (self.down_func(simu.x_coord_tensor[0,:], simu.y_coord_tensor[:,0], simu.cur_time) + gamma_down * simu.grid[-2,1:-1]) / (self.down_alpha + gamma_down)\n",
    "\n",
    "    def apply_nc(self, simu):\n",
    "        gamma_left = self.left_beta / simu.dx\n",
    "        gamma_right = self.right_beta / simu.dx\n",
    "        gamma_up = self.up_beta / simu.dx\n",
    "        gamma_down = self.down_beta / simu.dx\n",
    "\n",
    "        simu.grid[1:-1,0] = (self.left_func(simu.x_coord_tensor[0,:], simu.y_coord_tensor[:,0], simu.cur_time) - gamma_left * simu.grid[1:-1,1]) / (self.left_alpha - gamma_left)\n",
    "\n",
    "\n",
    "        # Right boundary\n",
    "        simu.grid[1:-1,-1] = (self.right_func(simu.x_coord_tensor[0,:], simu.y_coord_tensor[:,0], simu.cur_time) + gamma_right * simu.grid[1:-1,-2]) / (self.right_alpha + gamma_right)\n",
    "\n",
    "        # Left boundary\n",
    "        simu.grid[0,1:-1] = (self.up_func(simu.x_coord_tensor[0,:], simu.y_coord_tensor[:,0], simu.cur_time) - gamma_up * simu.grid[1,1:-1]) / (self.up_alpha - gamma_up)\n",
    "\n",
    "        # Down boundary\n",
    "        simu.grid[-1,1:-1] = (self.down_func(simu.x_coord_tensor[0,:], simu.y_coord_tensor[:,0], simu.cur_time) + gamma_down * simu.grid[-2,1:-1]) / (self.down_alpha + gamma_down)\n",
    "\n",
    "    @torch.compile(fullgraph=True)\n",
    "    def apply_ft(self, simu):\n",
    "        gamma_left = self.left_beta / simu.dx\n",
    "        gamma_right = self.right_beta / simu.dx\n",
    "        gamma_up = self.up_beta / simu.dx\n",
    "        gamma_down = self.down_beta / simu.dx\n",
    "\n",
    "        simu.grid[1:-1,0] = (self.left_func(simu.x_coord_tensor[0,:], simu.y_coord_tensor[:,0], simu.cur_time) - gamma_left * simu.grid[1:-1,1]) / (self.left_alpha - gamma_left)\n",
    "\n",
    "\n",
    "        # Right boundary\n",
    "        simu.grid[1:-1,-1] = (self.right_func(simu.x_coord_tensor[0,:], simu.y_coord_tensor[:,0], simu.cur_time) + gamma_right * simu.grid[1:-1,-2]) / (self.right_alpha + gamma_right)\n",
    "\n",
    "        # Left boundary\n",
    "        simu.grid[0,1:-1] = (self.up_func(simu.x_coord_tensor[0,:], simu.y_coord_tensor[:,0], simu.cur_time) - gamma_up * simu.grid[1,1:-1]) / (self.up_alpha - gamma_up)\n",
    "\n",
    "        # Down boundary\n",
    "        simu.grid[-1,1:-1] = (self.down_func(simu.x_coord_tensor[0,:], simu.y_coord_tensor[:,0], simu.cur_time) + gamma_down * simu.grid[-2,1:-1]) / (self.down_alpha + gamma_down)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "3937b5ecae05b2b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T14:38:43.922877Z",
     "start_time": "2025-05-06T14:38:43.914172Z"
    }
   },
   "source": [
    "class ContConduct:\n",
    "    def __init__(self, c_func):\n",
    "        self.c_func = c_func\n",
    "        self.map = None\n",
    "\n",
    "    @torch.compile\n",
    "    def make_conduct_map(self, simu):\n",
    "        # Initialize conduct map\n",
    "        self.map = torch.zeros(simu.grid.shape[0], simu.grid.shape[1], device=simu.device, dtype=simu.dtype)\n",
    "\n",
    "        # Get coordinates\n",
    "        x_coord = torch.arange(simu.x_grid, requires_grad=False, device=simu.device).expand(simu.y_grid, simu.x_grid) * simu.dx\n",
    "        y_coord = torch.arange(simu.y_grid, requires_grad=False, device=simu.device).unsqueeze(1).expand(simu.y_grid, simu.x_grid) * simu.dx\n",
    "\n",
    "        # Apply conductivity for interior\n",
    "        self.map[1:-1,1:-1] = self.c_func(x_coord, y_coord)\n",
    "\n",
    "        # Apply conductivity for boundary\n",
    "        self.map[0,:] = self.map[1,:] # up\n",
    "        self.map[-1,:] = self.map[-2,:] # down\n",
    "        self.map[:,0] = self.map[:,1] # left\n",
    "        self.map[:,-1] = self.map[:,-2] # right\n",
    "\n",
    "        # Compute harmonic mean conductivity\n",
    "        # left\n",
    "        self.map_left = 2 * self.map[1:-1,1:-1] * self.map[0:-2, 1:-1] / (self.map[1:-1,1:-1] + self.map[0:-2, 1:-1])\n",
    "\n",
    "        # right\n",
    "        self.map_right = 2 * self.map[1:-1,1:-1] * self.map[2:, 1:-1] / (self.map[1:-1,1:-1] + self.map[2, 1:-1])\n",
    "\n",
    "        # up\n",
    "        self.map_up = 2 * self.map[1:-1,1:-1] * self.map[1:-1, 0:-2] / (self.map[1:-1,1:-1] + self.map[1:-1, 0:-2])\n",
    "\n",
    "        # down\n",
    "        self.map_down = 2 * self.map[1:-1,1:-1] * self.map[1:-1, 2:] / (self.map[1:-1,1:-1] + self.map[1:-1, 2:])\n",
    "\n",
    "        self.merge_map = torch.stack([\n",
    "            self.map_left,\n",
    "            self.map_right,\n",
    "            self.map_up,\n",
    "            self.map_down\n",
    "        ], dim=0).unsqueeze(0)\n",
    "\n",
    "    def sanity_check(self, simu):\n",
    "        max_conduct = torch.max(self.map)\n",
    "        factor = simu.dt * max_conduct * 2 / simu.dx**2\n",
    "        if factor > 0.5:\n",
    "            raise ValueError(f'Improper setting for time steps and grid steps. The factor is {factor} and unstability will occur! Consider decrease the time step or increase the grid step.')\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "1e6cd78806121ead",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T14:38:43.951089Z",
     "start_time": "2025-05-06T14:38:43.931351Z"
    }
   },
   "source": [
    "class Heat2dSimu:\n",
    "    def __init__(self, map_shape, dx, total_time, tstep, bc, ic, c, plot_step, Q=0, device='cpu', do_progress_bar=True, dtype=torch.float32, if_debug=False, if_plot=True, msg_mute=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            map_shape (tuple): Physical size of the 2D domain.\n",
    "            step (float): Step size of *interior* points (excluding boundaries).\n",
    "            total_time (float): End time for the simulation.\n",
    "            tstep (int): Step size of time.\n",
    "            bc (iterable): Boundary condition with 4 elements. Order: up, r down, left, right.\n",
    "            ic (callable): Function for initial condition.\n",
    "            c (float): Diffusion coefficient.\n",
    "            plot_step (int): How often (in steps) to plot the solution.\n",
    "            device (str): 'cpu' or 'cuda', which device to use for Tensor operations.\n",
    "        \"\"\"\n",
    "        self.grid = None\n",
    "        self.grid_bach = None\n",
    "        self.map_shape = map_shape\n",
    "        self.dx = dx\n",
    "        self.total_time = total_time\n",
    "        self.dt = tstep\n",
    "        self.bc = bc\n",
    "        self.ic = ic\n",
    "        self.c = c\n",
    "        self.plot_step = plot_step\n",
    "        self.do_progress_bar = do_progress_bar\n",
    "        self.Q = self.make_heat_source_func(Q)\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        self.conv = None\n",
    "        self.if_debug = if_debug\n",
    "        self.decide_computation_mode()\n",
    "        self.cur_time = 0\n",
    "        self.if_plot = if_plot\n",
    "        self.do_progress_bar = do_progress_bar\n",
    "\n",
    "\n",
    "\n",
    "        # Check device\n",
    "        if torch.cuda.is_available() and device != 'cpu':\n",
    "            self.device = device\n",
    "\n",
    "        else:\n",
    "            self.device = 'cpu'\n",
    "\n",
    "\n",
    "        self.make_grid()\n",
    "\n",
    "        # Useful preload data\n",
    "        self.x_coord_tensor = torch.arange(self.x_grid, requires_grad=False, device=self.device).expand(self.y_grid, self.x_grid) * self.dx\n",
    "        self.y_coord_tensor = torch.arange(self.y_grid, requires_grad=False, device=self.device).unsqueeze(1).expand(self.y_grid, self.x_grid) * self.dx\n",
    "\n",
    "        # Some initialization\n",
    "        self.set_ic()\n",
    "        if isinstance(self.c, ContConduct):\n",
    "            self.c.make_conduct_map(self)\n",
    "\n",
    "        # Sanity check\n",
    "        self.sanity_check()\n",
    "\n",
    "    def sanity_check(self):\n",
    "        # Check conductivity\n",
    "        if isinstance(self.c, ContConduct):\n",
    "            self.c.sanity_check(self)\n",
    "        else:\n",
    "            factor = self.dt * c * 2 / self.dx**2\n",
    "            if factor > 0.5:\n",
    "                raise ValueError(f'Improper setting for time steps and grid steps. The factor is {factor} and unstability will occur! Consider decrease the time step or increase the grid step.')\n",
    "\n",
    "        # Check dt size setting\n",
    "        if self.dt > self.total_time/2:\n",
    "            raise ValueError('The time step is too big.')\n",
    "\n",
    "        # Check dx size setting\n",
    "        if self.dt > self.total_time/3:\n",
    "            raise ValueError('The grid step is too big.')\n",
    "\n",
    "    def make_heat_source_func(self, Q):\n",
    "        if callable(Q):\n",
    "            return torch.compile(Q)\n",
    "        else:\n",
    "            def func(x, y, t):\n",
    "                return Q\n",
    "            return torch.compile(func)\n",
    "\n",
    "    def set_ic(self):\n",
    "        # print(self.grid[1:-1,1:-1].shape)\n",
    "        self.grid[1:-1,1:-1] = self.ic(self.x_coord_tensor, self.y_coord_tensor)\n",
    "\n",
    "    def set_bc(self):\n",
    "        self.bc.apply(self)\n",
    "\n",
    "    def make_grid(self):\n",
    "        # Get size of grid\n",
    "        self.x_grid = math.ceil(self.map_shape[1] / self.dx)\n",
    "        self.y_grid = math.ceil(self.map_shape[0] / self.dx)\n",
    "        self.grid = torch.zeros(self.y_grid+2, self.x_grid+2, dtype=self.dtype, device=self.device)\n",
    "\n",
    "        # For convenience, prevent overhead for unsqueeze\n",
    "        self.grid_ch = self.grid.unsqueeze(0).unsqueeze(0).expand(1,1,-1,-1)\n",
    "\n",
    "    def make_conv_core_continuous(self):\n",
    "        self.conv = nn.Conv2d(1, 4, kernel_size=(3,3), bias=False, device=self.device, dtype=self.dtype)\n",
    "        dt_dx2 = self.dt / (self.dx**2)\n",
    "        kernel = torch.tensor([\n",
    "            [[ [0,0,0], [1,-1,0], [0,0,0] ]],\n",
    "            [[ [0,0,0], [0,-1,1], [0,0,0] ]],\n",
    "            [[ [0,1,0], [0,-1,0], [0,0,0] ]],\n",
    "            [[ [0,0,0], [0,-1,0], [0,1,0] ]]\n",
    "        ], device=self.device, dtype=self.dtype) * dt_dx2\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.conv.weight[:] = kernel\n",
    "\n",
    "    def make_conv_core_continuous2(self):\n",
    "        self.conv = [nn.Conv2d(1, 1, kernel_size=(3,3), bias=False, device=self.device, dtype=self.dtype) for i in range(4)]\n",
    "        dt_dx2 = self.dt / (self.dx ** 2)\n",
    "        kernel = [ [[[ [0,0,0], [1,-1,0], [0,0,0] ]]],\n",
    "                   [[[ [0,0,0], [0,-1,1], [0,0,0] ]]],\n",
    "                   [[[ [0,1,0], [0,-1,0], [0,0,0] ]]],\n",
    "                   [[[ [0,0,0], [0,-1,0], [0,1,0] ]]],]\n",
    "        with torch.no_grad():\n",
    "            for i in range(4):\n",
    "                self.conv[i].weight[:] = torch.tensor(kernel[i], device=self.device, dtype=self.dtype) * dt_dx2\n",
    "\n",
    "\n",
    "    def make_conv_core_const(self):\n",
    "        self.conv = nn.Conv2d(1, 1, kernel_size=(3,3), bias=False, device=self.device, dtype=self.dtype)\n",
    "        dt_dx2 = self.dt / (self.dx**2)\n",
    "        kernel = torch.tensor([\n",
    "            [[ [0,1,0], [1,-4,1], [0,1,0] ]],\n",
    "        ], device=self.device, dtype=self.dtype) * dt_dx2 * self.c\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.conv.weight[:] = kernel\n",
    "\n",
    "    def decide_computation_mode(self):\n",
    "        if isinstance(self.c, ContConduct):\n",
    "            if not self.if_debug:\n",
    "                self.update = self.update_continuous\n",
    "                self.make_conv_core_continuous()\n",
    "            else:\n",
    "                self.update = self.update_continuous2\n",
    "                self.make_conv_core_continuous()\n",
    "        else:\n",
    "            self.update = self.update_const\n",
    "            self.make_conv_core_const()\n",
    "\n",
    "\n",
    "\n",
    "    @torch.compile\n",
    "    def update_continuous(self):\n",
    "        with torch.inference_mode():\n",
    "            diff_map = self.conv(self.grid_ch)\n",
    "            diff = torch.sum(diff_map * self.c.merge_map, dim=1, keepdim=True) + self.Q(self.x_coord_tensor, self.y_coord_tensor, self.cur_time) * self.dt\n",
    "            self.grid_ch[:, :, 1:-1, 1:-1] += diff\n",
    "\n",
    "    @torch.compile\n",
    "    def update_continuous2(self):\n",
    "        with torch.inference_mode():\n",
    "            diff0 = self.conv[0](self.grid_ch)\n",
    "            diff1 = self.conv[1](self.grid_ch)\n",
    "            diff2 = self.conv[2](self.grid_ch)\n",
    "            diff3 = self.conv[3](self.grid_ch)\n",
    "\n",
    "            self.grid_ch[:, :, 1:-1, 1:-1] += diff0 + diff1 + diff2 + diff3 + self.Q(self.x_coord_tensor, self.y_coord_tensor, self.cur_time) * self.dt\n",
    "\n",
    "    def update_continuous_nc(self):\n",
    "        with torch.inference_mode():\n",
    "            diff_map = self.conv(self.grid_ch)\n",
    "            diff = torch.sum(diff_map * self.c.merge_map, dim=1, keepdim=True) + self.Q(self.x_coord_tensor, self.y_coord_tensor, self.cur_time) * self.dt\n",
    "            self.grid_ch[:, :, 1:-1, 1:-1] += diff\n",
    "\n",
    "    def update_continuous2_nc(self):\n",
    "        with torch.inference_mode():\n",
    "            diff0 = self.conv[0](self.grid_ch)\n",
    "            diff1 = self.conv[1](self.grid_ch)\n",
    "            diff2 = self.conv[2](self.grid_ch)\n",
    "            diff3 = self.conv[3](self.grid_ch)\n",
    "\n",
    "            self.grid_ch[:, :, 1:-1, 1:-1] += diff0 + diff1 + diff2 + diff3 + self.Q(self.x_coord_tensor, self.y_coord_tensor, self.cur_time) * self.dt\n",
    "\n",
    "    @torch.compile\n",
    "    def update_const(self):\n",
    "        with torch.inference_mode():\n",
    "            diff = self.conv(self.grid_ch)\n",
    "            self.grid_ch[:, :, 1:-1, 1:-1] += diff + self.Q(self.x_coord_tensor, self.y_coord_tensor, self.cur_time) * self.dt\n",
    "\n",
    "    def update_const_nc(self):\n",
    "        with torch.inference_mode():\n",
    "            diff = self.conv(self.grid_ch)\n",
    "            self.grid_ch[:, :, 1:-1, 1:-1] += diff + self.Q(self.x_coord_tensor, self.y_coord_tensor, self.cur_time) * self.dt\n",
    "\n",
    "    # @torch.compile\n",
    "    def start(self):\n",
    "        saved = []\n",
    "        append = saved.append\n",
    "        cur_max = -float('inf')\n",
    "        cur_min = float('inf')\n",
    "        with torch.inference_mode():\n",
    "            for step in tqdm(range( int(self.total_time/self.dt) ),disable=not self.do_progress_bar):\n",
    "                self.set_bc()\n",
    "                self.update()\n",
    "                self.cur_time += self.dt\n",
    "\n",
    "                if step % self.plot_step == 0:\n",
    "                    copied = self.grid[1:-1,1:-1].clone().to('cpu', non_blocking=True)\n",
    "                    if self.dtype == torch.bfloat16:\n",
    "                        copied = copied.to(dtype=torch.float32)\n",
    "                    append(copied)\n",
    "\n",
    "                    this_max = torch.max(copied)\n",
    "                    if cur_max < this_max:\n",
    "                        cur_max = this_max\n",
    "\n",
    "                    this_min = torch.min(copied)\n",
    "                    if cur_min > this_min:\n",
    "                        cur_min = this_min\n",
    "\n",
    "        # Append the very final result\n",
    "        copied = self.grid[1:-1,1:-1].clone().to('cpu')\n",
    "        if self.dtype == torch.bfloat16:\n",
    "            copied = copied.to(dtype=torch.float32)\n",
    "        append(copied)\n",
    "\n",
    "        if self.if_plot:\n",
    "            fig, axis = plt.subplots()\n",
    "\n",
    "\n",
    "            pcm = axis.pcolormesh(self.grid.to(dtype=torch.float32).cpu().numpy()[1:-1,1:-1], cmap=plt.cm.jet,\n",
    "                                  vmin=float(cur_min), vmax=float(cur_max))\n",
    "            plt.colorbar(pcm, ax=axis)\n",
    "            axis.set_xlabel('x grids')\n",
    "            axis.set_ylabel('y grids')\n",
    "\n",
    "\n",
    "\n",
    "            for i, data in enumerate(saved):\n",
    "                pcm.set_array(data.numpy())\n",
    "                axis.set_title(f'Distribution at t={i * self.plot_step * self.dt:.4f}')\n",
    "                plt.pause(0.01)\n",
    "\n",
    "            plt.show()\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "563d6bcef1e52425",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T15:04:27.617627Z",
     "start_time": "2025-05-06T15:04:27.610786Z"
    }
   },
   "source": [
    "map_shape=(torch.pi, torch.pi)\n",
    "dx = 0.05\n",
    "total_time=1\n",
    "dt=0.00005\n",
    "# dt = 0.05\n",
    "\n",
    "\n",
    "def ic(x,y):\n",
    "    return torch.sin(x) * torch.sin(y)\n",
    "    # return torch.sin(x)\n",
    "    # return 0\n",
    "c=0.5\n",
    "plot_step=100\n",
    "\n",
    "def Q(x,y,t):\n",
    "    # res = -torch.sin(5*x) * torch.sin(5*y) * torch.cos( torch.sqrt( (x-torch.pi/2)**2 + (y-torch.pi/2)**2) *4) * 5\n",
    "    # if t < 0.5:\n",
    "    #     return res\n",
    "    # return -res\n",
    "    return -torch.sin(5*x) * torch.sin(5*y) * torch.cos( torch.sqrt( (x-torch.pi/2)**2 + (y-torch.pi/2)**2) *4) * 5 * math.sin(t*torch.pi*8)\n",
    "\n",
    "factor = dt*c*2/dx**2\n",
    "print(factor)\n",
    "\n",
    "\n",
    "def func(x,y):\n",
    "    return 0.5\n",
    "con = ContConduct(func)\n",
    "\n",
    "\n",
    "def func2(x,y,t):\n",
    "    # return (torch.where(y < torch.pi/5, -1, 1) + torch.where(y > 2*torch.pi/5, -1, 1) - 1\n",
    "    #         + torch.where(y < 3*torch.pi/5, -1, 1) + torch.where(y > 4*torch.pi/5, -1, 1) - 1)\n",
    "    return (torch.where(y < torch.pi/4, 0, 1) + torch.where(y > 3*torch.pi/4, 0, 1) - 1)# * math.sin(4*torch.pi*t)\n",
    "    # return 0\n",
    "\n",
    "\n",
    "def func3(x,y,t):\n",
    "    # return (torch.where(x < torch.pi/5, -1, 1) + torch.where(x > 2*torch.pi/5, -1, 1) - 1 +\n",
    "    #         torch.where(x < 3*torch.pi/5, -1, 1) + torch.where(x > 4*torch.pi/5, -1, 1) - 1)\n",
    "    return (torch.where(x < torch.pi/4, 0, 1) + torch.where(x > 3*torch.pi/4, 0, 1) - 1)# * math.sin(4*torch.pi*t)\n",
    "    # return 0\n",
    "\n",
    "bc= BC_2D((1,0,func2),(1,0,func2),(1,0,func3),(1,0,func3))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019999999999999997\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T15:08:22.538139Z",
     "start_time": "2025-05-06T15:08:22.533891Z"
    }
   },
   "cell_type": "code",
   "source": "func2(torch.tensor([0]),torch.tensor([3*torch.pi/4]),0)\n",
   "id": "d8109db57fd01c89",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T08:28:20.004461Z",
     "start_time": "2025-05-06T08:28:20.001625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ratio_std(m_old, s_old, m_new, s_new):\n",
    "    ratio = 1 - m_new/m_old\n",
    "    n1 = (s_old**2 + s_new**2) / m_old**2\n",
    "    n2 = (m_old - m_new) * s_old / m_old**2\n",
    "    n2 = n2**2\n",
    "    sigma = math.sqrt(n1 + n2)\n",
    "    print(ratio*100, sigma*100)\n",
    "\n"
   ],
   "id": "bd8bb23e870a1604",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Experiment for Convolution #",
   "id": "efcc2ee2ba41f157"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Experiment on Constant Conductivity ##",
   "id": "9220a958aff39d62"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T07:06:26.488729Z",
     "start_time": "2025-05-06T07:06:08.796149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Constant conductivity (module test)\n",
    "print('====================================================================================')\n",
    "print('Module benchmark on constant conductivity update without @torch.compile')\n",
    "test = Heat2dSimu(map_shape, dx, total_time, dt, bc, ic, c, plot_step, Q, device='cuda', do_progress_bar=False, dtype=torch.float32, if_debug=False, if_plot=False, msg_mute=True)\n",
    "%timeit -r 10 -n 10000 test.update_const_nc()\n",
    "print('====================================================================================')\n",
    "print('Module benchmark on constant conductivity update with @torch.compile')\n",
    "test = Heat2dSimu(map_shape, dx, total_time, dt, bc, ic, c, plot_step, Q, device='cuda', do_progress_bar=False, dtype=torch.float32, if_debug=False, if_plot=False, msg_mute=True)\n",
    "%timeit -r 10 -n 10000 test.update_const()\n",
    "print('====================================================================================')"
   ],
   "id": "80e77225f32fe846",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================\n",
      "Module benchmark on constant conductivity update without @torch.compile\n",
      "112 μs ± 4.69 μs per loop (mean ± std. dev. of 10 runs, 10,000 loops each)\n",
      "====================================================================================\n",
      "Module benchmark on constant conductivity update with @torch.compile\n",
      "64.6 μs ± 3.15 μs per loop (mean ± std. dev. of 10 runs, 10,000 loops each)\n",
      "====================================================================================\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T08:24:23.630602Z",
     "start_time": "2025-05-06T08:24:23.623001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "m_old, s_old, m_new, s_new = 112, 4.69, 64.6, 3.15\n",
    "ratio_std(m_old, s_old, m_new, s_new)"
   ],
   "id": "dc23bbda143538bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.32142857142858 5.346591451679087\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Experiment on non-constant conductivity (merged kernel) ##",
   "id": "dededaa4f0ee8516"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T07:08:05.708660Z",
     "start_time": "2025-05-06T07:07:44.181665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Non-constant conductivity with merged kernel (module test)\n",
    "print('====================================================================================')\n",
    "print('Module benchmark on constant conductivity update with @torch.compile')\n",
    "test = Heat2dSimu(map_shape, dx, total_time, dt, bc, ic, con, plot_step, Q, device='cuda', do_progress_bar=False, dtype=torch.float32, if_debug=False, if_plot=False, msg_mute=True)\n",
    "%timeit -r 10 -n 10000 test.update_continuous()\n",
    "print('====================================================================================')\n",
    "print('Module benchmark on constant conductivity update without @torch.compile')\n",
    "test = Heat2dSimu(map_shape, dx, total_time, dt, bc, ic, con, plot_step, Q, device='cuda', do_progress_bar=False, dtype=torch.float32, if_debug=False, if_plot=False, msg_mute=True)\n",
    "%timeit -r 10 -n 10000 test.update_continuous_nc()\n",
    "print('====================================================================================')\n"
   ],
   "id": "a027e5598e504698",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================\n",
      "Module benchmark on constant conductivity update with @torch.compile\n",
      "69 μs ± 5.92 μs per loop (mean ± std. dev. of 10 runs, 10,000 loops each)\n",
      "====================================================================================\n",
      "Module benchmark on constant conductivity update without @torch.compile\n",
      "145 μs ± 4.6 μs per loop (mean ± std. dev. of 10 runs, 10,000 loops each)\n",
      "====================================================================================\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T08:25:31.010500Z",
     "start_time": "2025-05-06T08:25:31.005851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "m_old, s_old, m_new, s_new = 145, 4.6, 69, 5.92\n",
    "ratio_std(m_old, s_old, m_new, s_new)"
   ],
   "id": "ab3df7feace4b0f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.41379310344827 5.431203600083994\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Experiment on non-constant conductivity (split kernel) ##",
   "id": "84e99711ffe8c911"
  },
  {
   "cell_type": "code",
   "id": "69f6aed152bc8e29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T07:11:20.221837Z",
     "start_time": "2025-05-06T07:10:49.805978Z"
    }
   },
   "source": [
    "# Non-constant conductivity with split kernel (module test)\n",
    "print('====================================================================================')\n",
    "print('Module benchmark on constant conductivity update with @torch.compile')\n",
    "test = Heat2dSimu(map_shape, dx, total_time, dt, bc, ic, con, plot_step, Q, device='cuda', do_progress_bar=False, dtype=torch.float32, if_debug=False, if_plot=False, msg_mute=True)\n",
    "test.make_conv_core_continuous2()\n",
    "%timeit -r 10 -n 10000 test.update_continuous2()\n",
    "print('====================================================================================')\n",
    "print('Module benchmark on constant conductivity update without @torch.compile')\n",
    "test = Heat2dSimu(map_shape, dx, total_time, dt, bc, ic, con, plot_step, Q, device='cuda', do_progress_bar=False, dtype=torch.float32, if_debug=False, if_plot=False, msg_mute=True)\n",
    "test.make_conv_core_continuous2()\n",
    "%timeit -r 10 -n 10000 test.update_continuous2_nc()\n",
    "print('====================================================================================')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================\n",
      "Module benchmark on constant conductivity update with @torch.compile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0506 03:10:50.130000 26744 .conda\\Lib\\site-packages\\torch\\_inductor\\utils.py:1250] [1/1] Not enough SMs to use max_autotune_gemm mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 μs ± 28.6 μs per loop (mean ± std. dev. of 10 runs, 10,000 loops each)\n",
      "====================================================================================\n",
      "Module benchmark on constant conductivity update without @torch.compile\n",
      "187 μs ± 1.54 μs per loop (mean ± std. dev. of 10 runs, 10,000 loops each)\n",
      "====================================================================================\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "4ef75212be354b75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T08:26:26.255031Z",
     "start_time": "2025-05-06T08:26:26.248949Z"
    }
   },
   "source": [
    "m_old, s_old, m_new, s_new = 187, 1.54, 116, 28.6\n",
    "ratio_std(m_old, s_old, m_new, s_new)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.96791443850267 15.319464813251408\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "103d8e3849152ad4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T08:33:59.707186Z",
     "start_time": "2025-05-06T08:31:05.718126Z"
    }
   },
   "source": [
    "# Modular benchmark on boundary condition update\n",
    "print('====================================================================================')\n",
    "print('Module benchmark on boundary condition update with @torch.compile')\n",
    "test = Heat2dSimu(map_shape, dx, total_time, dt, bc, ic, c, plot_step, Q, device='cuda', do_progress_bar=False, dtype=torch.float32, if_debug=False, if_plot=False, msg_mute=True)\n",
    "%timeit -r 100 -n 10000 test.bc.apply(test)\n",
    "print('====================================================================================')\n",
    "print('Module benchmark on boundary condition update with @torch.compile(fullgraph=True)')\n",
    "test = Heat2dSimu(map_shape, dx, total_time, dt, bc, ic, c, plot_step, Q, device='cuda', do_progress_bar=False, dtype=torch.float32, if_debug=False, if_plot=False, msg_mute=True)\n",
    "%timeit -r 100 -n 10000 test.bc.apply_ft(test)\n",
    "print('====================================================================================')\n",
    "print('Module benchmark on boundary condition update without @torch.compile')\n",
    "print('====================================================================================')\n",
    "test = Heat2dSimu(map_shape, dx, total_time, dt, bc, ic, c, plot_step, Q, device='cuda', do_progress_bar=False, dtype=torch.float32, if_debug=False, if_plot=False, msg_mute=True)\n",
    "%timeit -r 100 -n 1000 test.bc.apply_nc(test)\n",
    "print('====================================================================================')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================\n",
      "Module benchmark on boundary condition update with @torch.compile\n",
      "56 μs ± 3.06 μs per loop (mean ± std. dev. of 100 runs, 10,000 loops each)\n",
      "====================================================================================\n",
      "Module benchmark on boundary condition update with @torch.compile(fullgraph=True)\n",
      "52.1 μs ± 4.06 μs per loop (mean ± std. dev. of 100 runs, 10,000 loops each)\n",
      "====================================================================================\n",
      "Module benchmark on boundary condition update without @torch.compile\n",
      "====================================================================================\n",
      "659 μs ± 22.5 μs per loop (mean ± std. dev. of 100 runs, 1,000 loops each)\n",
      "====================================================================================\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "9e4e4b1833f99cb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T08:34:43.843406Z",
     "start_time": "2025-05-06T08:34:43.838441Z"
    }
   },
   "source": [
    "m_old, s_old, m_new, s_new = 659, 22.5, 56, 3.06\n",
    "ratio_std(m_old, s_old, m_new, s_new)\n",
    "\n",
    "m_old, s_old, m_new, s_new = 659, 22.5, 52.1, 4.06\n",
    "ratio_std(m_old, s_old, m_new, s_new)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.50227617602428 4.65112829262162\n",
      "92.09408194233687 4.6822647247699845\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ee882e6b58cde0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bd4b0f010f12c026"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "57a3c90cb0f626fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "258e00b4f11284c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ba228e36bf920319"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1e7abcdaf37bcb9a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
