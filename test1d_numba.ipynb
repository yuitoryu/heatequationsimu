{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from numba import njit, cuda\n",
    "\n",
    "########################################\n",
    "# Numba Implementations for Interface Update\n",
    "########################################\n",
    "\n",
    "@njit\n",
    "def fix_interface_numba_cpu(grid, seg_indices, alphas, k_interface, c_dt_dx2):\n",
    "    \"\"\"\n",
    "    CPU version of the interface update using Numba.\n",
    "    Args:\n",
    "        grid (np.ndarray): 1D array of grid values.\n",
    "        seg_indices (np.ndarray): Interface indices (last index of left segment).\n",
    "        alphas (np.ndarray): Conductivities. Length = n_interfaces+1.\n",
    "        k_interface (np.ndarray): Computed interface conductivities.\n",
    "        c_dt_dx2 (float): Precomputed factor.\n",
    "    \"\"\"\n",
    "    for i in range(seg_indices.shape[0]):\n",
    "        idx = seg_indices[i]\n",
    "        i0 = grid[idx - 1]\n",
    "        i1 = grid[idx]\n",
    "        i2 = grid[idx + 1]\n",
    "        i3 = grid[idx + 2]\n",
    "        change1 = c_dt_dx2 * (k_interface[i] * (i2 - i1) + alphas[i] * (i0 - i1))\n",
    "        change2 = c_dt_dx2 * (alphas[i+1] * (i3 - i2) + alphas[i] * (i1 - i2))\n",
    "        grid[idx] = i1 + change1\n",
    "        grid[idx+1] = i2 + change2\n",
    "    return grid\n",
    "\n",
    "@cuda.jit\n",
    "def fix_interface_numba_gpu(grid, seg_indices, alphas, k_interface, c_dt_dx2):\n",
    "    \"\"\"\n",
    "    GPU version of the interface update using Numba CUDA.\n",
    "    This kernel is launched with 1D grid.\n",
    "    \"\"\"\n",
    "    i = cuda.grid(1)\n",
    "    if i < seg_indices.shape[0]:\n",
    "        idx = seg_indices[i]\n",
    "        # Direct indexing on device arrays\n",
    "        i0 = grid[idx - 1]\n",
    "        i1 = grid[idx]\n",
    "        i2 = grid[idx + 1]\n",
    "        i3 = grid[idx + 2]\n",
    "        change1 = c_dt_dx2 * (k_interface[i] * (i2 - i1) + alphas[i] * (i0 - i1))\n",
    "        change2 = c_dt_dx2 * (alphas[i+1] * (i3 - i2) + alphas[i] * (i1 - i2))\n",
    "        grid[idx] = i1 + change1\n",
    "        grid[idx+1] = i2 + change2\n",
    "\n",
    "########################################\n",
    "# Original Classes with Merged Numba Update\n",
    "########################################\n",
    "\n",
    "class BC_1D:\n",
    "    def __init__(self, left, right):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            left, right: (alpha, beta, f(t))\n",
    "        \"\"\"\n",
    "        self.left_alpha, self.left_beta, self.left_func = left\n",
    "        self.right_alpha, self.right_beta, self.right_func = right\n",
    "        \n",
    "    def apply(self, grid, dx, cur_time):\n",
    "        gamma_left = self.left_beta / dx\n",
    "        gamma_right = self.right_beta / dx\n",
    "        # Left boundary\n",
    "        grid[0] = (self.left_func(cur_time) - gamma_left * grid[1]) / (self.left_alpha - gamma_left)\n",
    "        # Right boundary\n",
    "        grid[-1] = (self.right_func(cur_time) + gamma_right * grid[-2]) / (self.right_alpha + gamma_right)\n",
    "\n",
    "class SegConduct:\n",
    "    def __init__(self, alphas, segs=[]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            alphas (list[float]): a list of conductivities\n",
    "            segs (list[float]): boundary of different conductivities\n",
    "        \"\"\"\n",
    "        self.alphas = alphas\n",
    "        self.segs = segs\n",
    "        self.conduct_map = None\n",
    "    \n",
    "    def sanity_check(self, simu):\n",
    "        # Check the validility of input conditions\n",
    "        \n",
    "        # Check if each segement can be assigned with a value or not\n",
    "        assert len(self.alphas) == len(self.segs) + 1, 'Number of conductivities does not match with number of segment bars.'\n",
    "        \n",
    "        # Check if seg bars are in legal order or not\n",
    "        jud = True\n",
    "        if len(self.segs) > 1:\n",
    "            for i in range(len(self.segs)-1):\n",
    "                if self.segs[i] >= self.segs[i+1]:\n",
    "                    jud = False\n",
    "                    break\n",
    "        assert jud, 'Value inside segment bars is not strictly monotonically increasing.'\n",
    "        \n",
    "        # Check if the seg bar range is still within the simulation grid or not\n",
    "        assert self.segs[-1] < simu.L - simu.dx and self.segs[0] > 0, 'Position of segment bars is out of simulation bound or too close to the boundary.'\n",
    "        \n",
    "        simu.if_seg = True\n",
    "    \n",
    "    def make_seg_index_and_calc_k_interface(self, simu):\n",
    "        # Location of the boundary index is the last index of the left segment\n",
    "        self.seg_index = []\n",
    "        self.k_interface = []\n",
    "        append1 = self.seg_index.append\n",
    "        append2 = self.k_interface.append\n",
    "        for i in range(len(self.segs)):\n",
    "            append1(math.floor(self.segs[i] / simu.dx))\n",
    "            append2( 2 * self.alphas[i] * self.alphas[i+1] / (self.alphas[i] + self.alphas[i+1]))\n",
    "  \n",
    "    def make_conduct_map(self, simu):\n",
    "        self.conduct_map = torch.zeros(simu.xstep)\n",
    "        # Assigning values\n",
    "        start = 0\n",
    "        for i in range(len(self.seg_index)):\n",
    "            end = self.seg_index[i] + 1\n",
    "            self.conduct_map[start:end] = self.alphas[i]\n",
    "            start = end\n",
    "        self.conduct_map[start:-1] = self.alphas[-1]\n",
    "        # print(simu.device)\n",
    "        self.conduct_map = self.conduct_map.to(simu.device)\n",
    "        # print(self.conduct_map.device)\n",
    "class Heat1dSimu:\n",
    "    def __init__(self, L, xstep, total_time, tstep, bc, ic, c, plot_step, device='cpu'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            L (float): Length of the 1D domain.\n",
    "            xstep (int): Number of interior points.\n",
    "            total_time (float): End time for simulation.\n",
    "            tstep (int): Number of time steps.\n",
    "            bc (BC_1D): Boundary condition object.\n",
    "            ic (callable): Function for initial condition.\n",
    "            c (float or SegConduct): Diffusion coefficient (uniform or piecewise).\n",
    "            plot_step (int): Steps between plots.\n",
    "            device (str): 'cpu' or 'cuda'.\n",
    "        \"\"\"\n",
    "        self.L = L\n",
    "        self.xstep = xstep\n",
    "        self.total_time = total_time\n",
    "        self.tstep = tstep\n",
    "        self.bc = bc\n",
    "        self.ic = ic\n",
    "        self.c = c\n",
    "        self.device = device\n",
    "        self.cur_time = 0.0\n",
    "        self.plot_step = plot_step\n",
    "        self.if_seg = False\n",
    "\n",
    "        # Discretization\n",
    "        self.dx = L / (xstep + 0)  # note: ensure correct division for your case\n",
    "        self.dt = total_time / tstep\n",
    "        if isinstance(self.c, SegConduct):\n",
    "            self.c.sanity_check(self)\n",
    "            self.c.make_seg_index_and_calc_k_interface(self)\n",
    "            self.c.make_conduct_map(self)\n",
    "            self.c.conduct_map = self.c.conduct_map.to(self.device)\n",
    "            mul = 1\n",
    "        else:\n",
    "            mul = c\n",
    "            print('Uniform conductivity')\n",
    "        self.c_dt_dx2 = mul * self.dt / (self.dx ** 2)\n",
    "\n",
    "        # Solution array (including boundaries)\n",
    "        self.grid = torch.zeros(xstep + 2, device=self.device)\n",
    "\n",
    "        # Set initial condition\n",
    "        self.set_ic()\n",
    "\n",
    "        # Define convolution kernel (for the interior update)\n",
    "        self.conv = nn.Conv1d(1, 1, kernel_size=3, bias=False, device=self.device)\n",
    "        with torch.no_grad():\n",
    "            self.conv.weight[:] = self.c_dt_dx2 * torch.tensor([[[1, -2, 1]]], dtype=torch.float, device=self.device)\n",
    "\n",
    "    def conduct_seg_sanity_check(self):\n",
    "        if self.if_seg:\n",
    "            self.c.sanity_check(self)\n",
    "        elif not isinstance(self.c, int):\n",
    "            raise TypeError('Expected int or SegConduct object.')\n",
    "\n",
    "    def set_bc(self):\n",
    "        \"\"\"Apply boundary conditions.\"\"\"\n",
    "        self.bc.apply(self.grid, self.dx, self.cur_time)\n",
    "\n",
    "    def set_ic(self):\n",
    "        \"\"\"Initialize interior points using the initial condition function.\"\"\"\n",
    "        x_interior = torch.linspace(self.dx, self.dx * self.xstep, self.xstep, device=self.device)\n",
    "        self.grid[1:-1] = self.ic(x_interior)\n",
    "\n",
    "    def update(self):\n",
    "        \"\"\"Perform one time step update.\"\"\"\n",
    "        self.set_bc()\n",
    "        \n",
    "        interface_list = self.record_interface()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            input_for_conv = self.grid.view(1, 1, -1)\n",
    "            second_diff = self.conv(input_for_conv).view(-1)\n",
    "            if self.if_seg:\n",
    "                second_diff *= self.c.conduct_map\n",
    "            self.grid[1:-1] += second_diff\n",
    "        \n",
    "        if self.if_seg:\n",
    "            # Update the interfaces using Numba\n",
    "            self.update_interface_numba()\n",
    "        \n",
    "        self.cur_time += self.dt\n",
    "\n",
    "    def update_interface_numba(self):\n",
    "        \"\"\"\n",
    "        Use Numba to update the grid at the interface points.\n",
    "        Dispatch to CPU or GPU version based on self.device.\n",
    "        \"\"\"\n",
    "        # Prepare data as numpy arrays\n",
    "        seg_indices_np = np.array(self.c.seg_index, dtype=np.int64)\n",
    "        alphas_np = np.array(self.c.alphas, dtype=np.float32)\n",
    "        k_interface_np = np.array(self.c.k_interface, dtype=np.float32)\n",
    "        \n",
    "        if self.device == 'cpu':\n",
    "            # For CPU, move grid to numpy, update, then convert back.\n",
    "            grid_np = self.grid.cpu().numpy().astype(np.float32)\n",
    "            grid_np = fix_interface_numba_cpu(grid_np, seg_indices_np, alphas_np, k_interface_np, self.c_dt_dx2)\n",
    "            self.grid = torch.from_numpy(grid_np).to(self.device)\n",
    "        else:\n",
    "            # For GPU, wrap the grid via __cuda_array_interface__\n",
    "            grid_dev = cuda.as_cuda_array(self.grid)\n",
    "            seg_indices_dev = cuda.to_device(seg_indices_np)\n",
    "            alphas_dev = cuda.to_device(alphas_np)\n",
    "            k_interface_dev = cuda.to_device(k_interface_np)\n",
    "            threads_per_block = 32\n",
    "            blocks_per_grid = (len(seg_indices_np) + (threads_per_block - 1)) // threads_per_block\n",
    "            fix_interface_numba_gpu[blocks_per_grid, threads_per_block](\n",
    "                grid_dev, seg_indices_dev, alphas_dev, k_interface_dev, self.c_dt_dx2\n",
    "            )\n",
    "            # grid_dev is a view of self.grid, so self.grid is updated in place.\n",
    "\n",
    "    def record_interface(self):\n",
    "        \"\"\"Optional: record interface neighborhoods as a list of tensors.\"\"\"\n",
    "        return [self.grid[seg-1:seg+3] for seg in self.c.seg_index]\n",
    "            \n",
    "    def start(self, do_plot=True):\n",
    "        \"\"\"Run the simulation and optionally plot the solution.\"\"\"\n",
    "        if do_plot:\n",
    "            fig, ax = plt.subplots(figsize=(8, 5))\n",
    "            cmap = plt.cm.plasma\n",
    "            norm = plt.Normalize(vmin=0, vmax=self.total_time)\n",
    "            sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "            sm.set_array([])\n",
    "\n",
    "        for step in tqdm(range(self.tstep),disable=True):\n",
    "            self.update()\n",
    "            if do_plot and step % self.plot_step == 0:\n",
    "                current_time = step * self.dt\n",
    "                color = cmap(norm(current_time))\n",
    "                ax.plot(self.grid.cpu().numpy(), color=color, label=f't={current_time:.2f}')\n",
    "\n",
    "        if do_plot:\n",
    "            cbar = fig.colorbar(sm, ax=ax, label='Time')\n",
    "            ax.set_xlabel(\"Grid Index\")\n",
    "            ax.set_ylabel(\"Temperature\")\n",
    "            ax.set_title(\"1D Heat Equation Evolution\")\n",
    "            ax.grid(True)\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ic(x):\n",
    "    return torch.sin(2*x)\n",
    "\n",
    "def left(t):\n",
    "    return 0\n",
    "\n",
    "def right(t):\n",
    "    return 0\n",
    "\n",
    "bc = BC_1D((1,0,left), (1,0,right)) \n",
    "L = math.pi\n",
    "xstep = 100\n",
    "total_time = 0.5\n",
    "tstep = 3200\n",
    "# c = 1\n",
    "num = 6\n",
    "c = SegConduct([0.1*i for i in range(1,num+1)], [math.pi/num*i for i in range(1,num)])\n",
    "# factor = c * total_time / tstep /(L / (xstep + 1))**2\n",
    "plot_step = 80\n",
    "# print(factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target(L, xstep, total_time, tstep, bc, ic, c, plot_step):\n",
    "    test = Heat1dSimu(L, xstep, total_time, tstep, bc, ic, c, plot_step, 'cuda')\n",
    "    test.start(do_plot=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.68 s ± 31.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit target(L, xstep, total_time, tstep, bc, ic, c, plot_step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
